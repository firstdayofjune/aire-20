\section{Analysis / Our approach} % (fold)
\label{sec:own_approach}

The \crowdre{} dataset is available in form of a MySQL database dump, but the tables can also be downloaded separated into several \textit{.csv} files\footnote{\url{https://crowdre.github.io/murukannaiah-smarthome-requirements-dataset/}, last visited 2020-01-15}. For our research, we were only interested in the pure requirement sentences (without any ratings, or user characterization added to the data). We could therefore reconstructed the sentences from the \textit{requirements.csv} file only, which is included in the downloaded data.

\colorbox{yellow!30}{ToDo:} Give the approach a name as title!

\subsection{NLP Preprocessing Pipeline} % (fold)
\label{sub:own_pipeline}

- Tokenization
- Stop-Word-Removal
- Stemming
Data cleansing:
- Remove special characters (spaces, dots, apostrophes, slashes), because otherwise they would have been ranked in the bag of words
- Bag of words
- TF/IDF
% subsection preprocessing (end)

\subsection{LDA Approach} % (fold)
\label{sub:own_lda}
- how do we process the LDA on our dataset

\subsection{Neural Network} % (fold)
\label{sub:own_neuralnetwork}

\colorbox{yellow!30}{ToDo:} How does our approach with the Neural Network looks like?
