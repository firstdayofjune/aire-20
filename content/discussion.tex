\section{Discussion}
\label{sec:discussion}
As expected, our dataset was probably too small to achieve any better results. In this context, it is important to know how the accuracy of the word2vec phrase detection dropped to 66\% when Mikolov et al. trained their model on a "smaller" dataset of 6 billion words\cite[p7]{mikolov_distributed_2013}. \emph{Smaller} at least in comparison to their final training set, but this is still a lot larger than our dataset by a factor of almost 120.000.

Also, all our word2vec approaches required to post-process the results using PCA. Though the PCA is a technique which is known for how well it can preserve the original information, some of the information will inevitably get lost. Our results may therefore have been impacted by the dimensionality reduction.

More time would have been needed for the evaluation of our results. Both the tags, as well as the application domains were set by the crowd-workers themselves. The quality of these assignemnts has not been proven yet and we used this data only for lack of proper testing data. For example, one of the requirements with the content "I want my smart home to sync with my biorhythm app and turn on some music that might suit my mood when I arrive home from work so that I can be relaxed" was related to the emph{Entertainment} domain. In our last approach this sentence was found to be in the \emph{Health} domain using the Word Mover's Distance. We could not say that this assignement was definitely wrong, though. So it could be we find our approach a lot more successful after a thorough analysis of all the clusters.

Finally, we lacked prior knowledge of the field of topic modeling and machine learning in general. Though we performed our research with technical and professional care in all conscience and under consideration of commonly accepted principles, there may be a lot of potential for further optimization (which goes beyond changing the hyper-parameters of our models). Future works could be done on an improved set of data, by only analyzing those requirements which have clearly defined domains. Such dataset could be achieved, by cleaning the current \crowdre{} dataset by the means of manually labeling the requirement sentences. This includes verifying the currently assigned application domains, reassigning some domains and also creating new domains, which may not have been in the domain-selection when the requirements were created.\\[2cm]