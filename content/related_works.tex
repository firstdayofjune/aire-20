\section{Related Work} % (fold)
\label{sec:related_work}

Using an Latent Dirichlet Allocation for topic modeling is not a new idea. Also Zhou et. al in \cite{zhou_tong_text_2016} used this technique to automate a part of text mining. They used two different data for their research. At first they focus on articles from Wikipedia where they evaluated over 200.000 articles. They found out that from 50 topcis there are three topics with high probabilities compared to the others. They also used twitter messages from a set of 10.000 users. They found 30 topics five topics with the highest probabilities of the set of topics. They also mentioned that the processing time of their approach took quite long and might be improved in future works.


There are also researches using different techniques to get a topic model from a large amount of documents. George et. al in \cite{george_unsupervised_2018} proposed to use a 2D vector space model. They took over 300 unclassified document from 20 newsgroups dataset. As conclusion they mentioned that the performance of the algorithm need to be increased in future as the computation time consumes a lot of time.


Building up a pre-processing pipeline for our model approach was also performed in a similar way by other researchers. As Gemko et. al in \cite{gemkow_automatic_2018} described they used also pre-processing for the automatic glossary term extraction. Their pipeline contains the steps of Tokenization, POS-Tagging, CHunking and Lemmatization. Additionally they apply some relevance filtering and specificity filtering afterwards. They also used the CrowdRE dataset and got well prepared data from their pre-processing pipeline to work with for their glossary term extraction. In they conclusion they figure out that the approach is generalized and not specific for the dataset so it can be used for any kind of data. Also it might be possible to add several filter stages to the pipeline to get reasonable data for the specific task that shall be performed afterwards.

\colorbox{yellow!30}{ToDo:} Add references to papers that have a similar approach...

- Paper about LDA for topic modeling

In 2010, {\v R}eh{\r u}{\v r}ek et al. wanted to automatically create a short list of similar articles to a given article\cite{rehurek_software_2010}. They used Latent Semantic Analysis, as well as LDA in their approach and created a Python library called \emph{gensim}\footnote{\url{https://radimrehurek.com/gensim/index.html}, last visited 2020-01-19\label{fn:gensim_website}}, which aimed at implementing these techniques in a clear, efficient and scalable way\footnote{\url{https://radimrehurek.com/gensim/about.html}, last visited 2020-01-19}.