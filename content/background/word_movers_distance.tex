\subsubsection{Word Mover's Distance} % (fold)
\label{sub:word_movers_distance}
While word2vec is very sophisticated when it comes to generating quaility word embeddings, the method still has its weaknesses. Consider the two documents: \emph{"My smart home should turn on my favorite music when I come to my home."} and \emph{"My smart home shall play my most favored songs when I arrive at my place."} The sentences basically convey the same information. Plotting these sentences with word embeddings, some of their vectors will even be close. Especially if word-wise similarity is given, as e.g. with the pairs $< music, songs>$, $<come, arrive>$. The closeness of the sentences as a whole, though, can not be represented in the word2vec model alone. To overcome this shortage, Kusner et al. introduced the Word Mover's Distance (WMD) in 2015 \cite{kusner_word_2015}. The WMD is a distance function which can be used to calculate the distance between these kind of text documents. Based on previously created word embeddings (as for example those from word2vec), the \textit{"distance be- tween[sic!] two text documents A and B is the minimum cumu- lative[sic!] distance that words from document A need to travel to match exactly the point cloud of document B"}\cite[p2]{kusner_word_2015}. Using this method, the WMD reaches a high retrieval accuracy, while being completely free of hyper-parameters and therefore straight-forward to use.