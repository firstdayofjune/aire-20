\section{Analysis}
The \crowdre{} dataset is available in form of a MySQL database dump. As an alternative, the tables can also be downloaded separated into several \textit{.csv} files. As we aim to analyze the datasat using unsupervised learning techniques, we were only interested in the pure requirements (without any ratings, classifications or other user characterization added to the data whatsover). Using the \textit{.csv} files was therefore sufficient for us and the following analysis is based on the reconstructed requirements that were generated from with the template. The template was given as follows: As a [role] I want [feature] so that [benefit]. The missing parts are taken from the file \textit{requirements.csv} as they were entered into the template.

\subsection{NLP}

To compare the data we choose the Brown Dataset which is a huge dataset that was taken from books and articles. 

\begin{wraptable}{r}{7.5cm}
\centering
\begin{tabular}{ | l | c | c | }
\specialrule{.05em}{1em}{0em} 
\thead{Indicator} & \thead{\crowdre{}} & \thead{Brown} \\ \specialrule{.15em}{0em}{0em}
\makecell{Number of Tokens \\ (unique)} & \makecell[c]{90844 \\ (5024)} & 1034378 \\ \hline
Number of Lexical Words & 52266 & 542924 \\ \hline
\makecell{Vocabulary Size \\ (Lexical Words)} & 4906 & 46018 \\ \hline
Vocabulary Size (Stems) & 3398 & 29,846 \\ \hline
\makecell{Average Sentence Length \\ (Tokens)} & 31 & 18 \\ \hline
\makecell{Average Sentence Length \\ (Lexical Words)} & 18 & 10 \\ \hline
Lexical Diversity & 0.011 & 0.054 \\ \hline
\end{tabular}
\caption{Data from the analysis of the \crowdre{} dataset}\label{tbl-dataset-analysis}
\end{wraptable}


In \autoref{tbl-dataset-analysis} we can see the number of tokens and lexical words is much bigger in the Brown dataset as the diversity of words is higher in this kind of text. But it's also because the dataset is much bigger than the \crowdre{} dataset. Also obvious is that the sentence length at the requirements is lower as they tend to be formulated short and simple. Additionally the lexical diversity is also less as often the same words are used to write down requirements. And it is also necessary to use unique words for the description of the same feature to avoid ambiguity. To sum up we can say that the results are as expected from a dataset that contains only requirements.


\subsection{Preprocessing} % (fold)
\label{sub:preprocessing}
- Bag of words
- Remove speical characters (spaces, dots, apostrophes, slashes), because otherwise they would have been ranked in the bag of words
% subsection preprocessing (end)