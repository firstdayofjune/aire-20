\begin{abstract}
% Im Abstract geht man im kleinen eigentlich genauso vor wie in dem gesamten Paper: Erst ein, zwei Sätze zur Motivation, dann die Methodik erklären, den Datensatz erwähnen und anschließend ein kurzer Abschnitt zu den Ergebnissen und Schlüssen die man aus der Arbeit ziehen kann %

%% Motivation
%
%% Methodology
%
%% Dataset
%
%% Findings
%
%% Conclusion
%

% Future Work nicht ins Abstract!
We aimed to automatically derive topics from a dataset of 2966 requirement sentences. The requirements were previously collected, tagged and categorized by crowd workers as part of the \crowdre{} project. We preprocessed the data in an NLP pipeline using state of the art NLP methods and applied topic modeling techniques to the results in order to cluster the data. This includes Latent Dirichclet Allocation, word embeddings using word2vec and the recently published Word Mover's Distance. We visiualized our findings in 2D scatter plots with the help of Principal Component Analysis and Stochastic Neighbor Embedding (t-SNE). All our programming work was done in Python and is strongly dependend on the nltk and gensim library.
The requirement sentences had 5 different domains already assigned to them (including a domain called \emph{Other}, which was neither of the other 4). Thus we expected to find 4 different clusters, with some noise between them, caused by the requirements of the \emph{Other} domain. Having followed several approaches for topic modeling we found out that the Word Mover's Distance is probably the most promising, still we were only able to find 3 reasonably distinct clusters. The final verification, whether this means the pre-assigned categories are wrong or the dataset is too small for an automated topic modeling (or a combination of both) is a manual process and may be part of future work.
\end{abstract}