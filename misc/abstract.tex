\begin{abstract}
% Im Abstract geht man im kleinen eigentlich genauso vor wie in dem gesamten Paper: Erst ein, zwei Sätze zur Motivation, dann die Methodik erklären, den Datensatz erwähnen und anschließend ein kurzer Abschnitt zu den Ergebnissen und Schlüssen die man aus der Arbeit ziehen kann %

%% Motivation
%
%% Methodology
%
%% Dataset
%
%% Findings
%
%% Conclusion
%

% Future Work nicht ins Abstract!
In this paper, we work on a data challenge declared by Murukannaiah et al. on how to automatically summarize crowd-sourced requirements\,\cite{murukannaiah_toward_2017}. A challenge which hinders the decision-making process in data-driven requirements engineering. Our work is based on a dataset of 2966 requirement sentences, which was collected in 2016, by asking crowd workers to write and categorize smart home requirements. According to these categories, we expect to summarize the data into 4 different clusters. Before clustering, we process the requirements data using natural language processing, i.e. tokenization, stop-word-removal, stemming, Bag-of-Words and TF-IDF. Then, we propose three approaches which can automatically derive topics from the given dataset: Latent Dirichlet Allocation, a combination of word embeddings (created using word2vec) \& principal component analysis and a combination of word embeddings \& the recently published Word Mover's Distance. Ordered by the quality of their results, the last of these approaches is the most promising, but also the most expensive one. Though we do not identify 4 cluster, we find the requirements to be separated into meaningful clusters when visualizing our results in 2D scatter plots using Stochastic Neighbor Embedding (t-SNE). 
Depending on the word embeddings we use in our approach, we manage to cluster the requirements in two ways: one which is closer to the original categorization and another, which allows new insights into the dataset, e.g. to find potentially new categories. Unfortunately, no measure exists to rate the quality of our results. Still, our findings are a first solution to the summarization challenge and can be the basis for future work in the direction of crowd sourcing requirements.
\end{abstract}