{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "\n",
    "# nltk.download('book')\n",
    "# nltk.download('brown')\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "CROWD_RE_REQUIREMENTS = Path('..', 'crowdre_cleaned-csv', 'requirements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Requirement(object):\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    def tokenize(self):\n",
    "        self.tokens = nltk.word_tokenize(self.text)\n",
    "    \n",
    "    def redundant_start(self):\n",
    "        self.starts_with_smart_home = self.text.lower().startswith(\"my smart home to\")\n",
    "        if self.starts_with_smart_home:\n",
    "            self.cleaned_text = self.text[16:]\n",
    "        else:\n",
    "            self.cleaned_text = self.text\n",
    "    \n",
    "    def remove_stopwords(self):\n",
    "        self.lexical_words = [word for word in self.tokens if word not in stopwords.words('english')]\n",
    "        \n",
    "    def complete_analysis(self):\n",
    "        self.tokenize()\n",
    "        self.redundant_start()\n",
    "        self.remove_stopwords()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequirementsList(object):\n",
    "    def __init__(self, path):\n",
    "        if not path.exists() and path.is_file():\n",
    "            raise(\"The given path does not exist or is not a file.\")\n",
    "        self._build_requirements_list(path)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.requirements.__iter__() if hasattr(self, 'requirements') else []\n",
    "\n",
    "    def _build_requirements_list(self, path):\n",
    "        self.requirements = []\n",
    "        with open(path, newline='') as requirements_csv:\n",
    "            re_reader = csv.DictReader(requirements_csv, delimiter=',')\n",
    "            for row in re_reader:\n",
    "                requirementText = \"As a \" + row['role'] + \" I want \" + row['feature'] + \" so that \" + row['benefit']\n",
    "                requirement = Requirement(requirementText)\n",
    "                self.requirements.append(requirement)\n",
    "\n",
    "    def count(self):\n",
    "        return len(self.requirements) if hasattr(self, 'requirements') else 0\n",
    "\n",
    "re_list = RequirementsList(CROWD_RE_REQUIREMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP analysis\n",
    "joined_text = \" \".join(map(lambda re: re.text, re_list.requirements))\n",
    "joined_text_tokenized = nltk.word_tokenize(joined_text)\n",
    "\n",
    "no_of_requirements = re_list.count()\n",
    "tokens = []\n",
    "lexical_words = []\n",
    "re_starting_with_smart_home = 0\n",
    "\n",
    "lexical_words = []\n",
    "\n",
    "for requirement in re_list:\n",
    "    requirement.complete_analysis()\n",
    "    tokens += requirement.tokens    \n",
    "    lexical_words += requirement.lexical_words    \n",
    "    if requirement.starts_with_smart_home:\n",
    "        re_starting_with_smart_home += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lancester = LancasterStemmer()\n",
    "porter = PorterStemmer()\n",
    "stems_lancester = []\n",
    "stems_porter = []\n",
    "for token in tokens:\n",
    "    stems_lancester.append(lancester.stem(token))\n",
    "    stems_porter.append(porter.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens (unique): \t\t35747 (3519)\n",
      "Number of Lexical Words: \t\t20178\n",
      "\n",
      "Vocabulary Size (Lexical Words): \t3411\n",
      "Vocabulary Size (Stems): \t\t2461\n",
      "\n",
      "Average Sentence Length (Tokens): \t12\n",
      "Average Sentence Length (Lexical Words): 7\n",
      "\n",
      "Lexical Diversity: \t\t\t0.018\n",
      "Requirements starting with\n",
      "\t'I want my smart home to...': \t410/2966 (13.82%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Tokens (unique): \\t\\t{} ({})\".format(len(tokens), len(set(tokens))))\n",
    "print(\"Number of Lexical Words: \\t\\t{}\".format(len(lexical_words)))\n",
    "\n",
    "print(\"\\nVocabulary Size (Lexical Words): \\t{}\".format(len(set(lexical_words))))\n",
    "print(\"Vocabulary Size (Stems): \\t\\t{}\".format(len(set(stems_porter))))\n",
    "\n",
    "print(\"\\nAverage Sentence Length (Tokens): \\t{}\".format(round(len(tokens) / no_of_requirements)))\n",
    "print(\"Average Sentence Length (Lexical Words): {}\".format(round(len(lexical_words) / no_of_requirements)))\n",
    "\n",
    "print(\"\\nLexical Diversity: \\t\\t\\t{}\".format(round(len(set(lexical_words)) / len(joined_text),3)))\n",
    "print(\"Requirements starting with\\n\\t'I want my smart home to...': \\t{}/{} ({}%)\".format(re_starting_with_smart_home, no_of_requirements, round(re_starting_with_smart_home / no_of_requirements * 100, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
